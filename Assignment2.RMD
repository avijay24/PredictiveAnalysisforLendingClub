---
title : "Assignment2"
author: "Anisha Vijayan (UIN: 662618335)"
        "Preethi Srinivasan (UIN: 663981973)"
date  : "3/06/2022"
output: html_document
---
  
```{r setup}
library(tidyverse)
library(lubridate)
library(dplyr)
library(magrittr)
library(caret)
library(ROCR)
library(xgboost)
library(rpart)
library(caret)
library(ranger)
library(glmnet)
library(vip)
library(ROSE)
library(gbm)
library(DiagrammeR)
library(rsvg)
library(DiagrammeRsvg)

lcdf <- read_csv('lcDataSample.csv')
options(digits = 4)  # to set the total digits to display as 4  (decimals will be displayed upto 2 decimal places)

```


```{r Data Clean up from Asgnt1}

#for converting char cols to date format
lcdf$issue_d # already in date format

lcdf$last_credit_pull_d 
lcdf$last_credit_pull_d  <- paste(lcdf$last_credit_pull_d , "-01", sep = "")
lcdf$last_credit_pull_d  <- parse_date_time(lcdf$last_credit_pull_d , "myd")

lcdf$earliest_cr_line    
lcdf$earliest_cr_line <- paste(lcdf$earliest_cr_line, "-01", sep = "")
lcdf$earliest_cr_line <- parse_date_time(lcdf$earliest_cr_line, "myd")

lcdf$next_pymnt_d
lcdf$next_pymnt_d <- paste(lcdf$next_pymnt_d, "-01", sep = "")
lcdf$next_pymnt_d <- parse_date_time(lcdf$next_pymnt_d, "myd")

#Considering only Charged Off and Fully Paid Loans
lcdf <- lcdf %>% filter(loan_status == "Charged Off" | loan_status == "Fully Paid")

#converting character columns to Category
lcdf <- lcdf %>% mutate_if(is.character, as.factor)

#converting last payment received date to a date type variable
lcdf$last_pymnt_d<-paste(lcdf$last_pymnt_d, "-01", sep = "")
lcdf$last_pymnt_d<-parse_date_time(lcdf$last_pymnt_d,  "myd")

#to calculate actual term
lcdf$actualTerm <- ifelse(lcdf$loan_status == "Fully Paid", as.duration(lcdf$issue_d %--% lcdf$last_pymnt_d)/dyears(1), 3)

#calculate the annualized percentage return
lcdf$annRet <- ((lcdf$total_pymnt - lcdf$funded_amnt)/lcdf$funded_amnt)*(12/36)*100

#considering this actual term, the actual annual return is
lcdf$actualReturn <- ifelse( lcdf$actualTerm > 0,
((lcdf$total_pymnt - lcdf$funded_amnt)/lcdf$funded_amnt)*(1/lcdf$actualTerm)*100, 0)

#some of category levels have very few examples
# so we have recoded such categories with very few cases to "other"
lcdf$purpose <- fct_recode(lcdf$purpose, other = "wedding", other = "renewable_energy")

#convert emp_length to factor -- with factor levels ordered in a meaningful way
lcdf$emp_length <- factor(lcdf$emp_length, levels = c("n/a", "< 1 year","1 year","2 years", "3 years" ,  "4 years",   "5 years",   "6 years",   "7 years" ,  "8 years", "9 years", "10+ years" ))

#Derived attributes
#Proportion of satisfactory bankcard accounts 
lcdf$propSatisBCAccts <- ifelse(lcdf$num_bc_tl > 0, lcdf$num_bc_sats/lcdf$num_bc_tl, 0)

#length of borrower's history with LC i.e time between earliest_cr_line and issue_d
lcdf$borrHistory <- as.duration(lcdf$earliest_cr_line %--% lcdf$issue_d  ) / dyears(1)

#Ratio of openAccounts to totalAccounts
lcdf$ratioOpenAccount <- ifelse(lcdf$open_acc > 0, lcdf$open_acc/lcdf$total_acc, 0)

##MISSING VALUES
# to handle missing values
lcdf <- lcdf %>% select_if(function(x){ ! all(is.na(x)) } )

#Suppose you decide to remove variables which have more than 60% missing values
nm<-names(lcdf)[colMeans(is.na(lcdf))>0.6]
lcdf <- lcdf %>% select(-all_of(nm))
#summary of data in these columns
nm<- names(lcdf)[colSums(is.na(lcdf))>0]
summary(lcdf[, nm])

lcdf<- lcdf %>% replace_na(list(mths_since_last_delinq=-500, bc_open_to_buy=median(lcdf$bc_open_to_buy, na.rm=TRUE), mo_sin_old_il_acct=1000, mths_since_recent_bc=1000, mths_since_recent_inq=50, num_tl_120dpd_2m = median(lcdf$num_tl_120dpd_2m, na.rm=TRUE),percent_bc_gt_75 = median(lcdf$percent_bc_gt_75, na.rm=TRUE), bc_util=median(lcdf$bc_util, na.rm=TRUE) ))

#Variables with missing values
nm<-names(lcdf)[colMeans(is.na(lcdf))>0]
glimpse(lcdf %>% select(nm))

lcdf<- lcdf %>% mutate_if(is.numeric,  ~ifelse(is.na(.x), median(.x, na.rm = TRUE), .x))

#Identify the variables to remove
varsToRemove = c('funded_amnt_inv', 'term', 'emp_title', 'pymnt_plan', 'earliest_cr_line', 'title', 'zip_code', 'addr_state', 'out_prncp', 'out_prncp_inv', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'last_credit_pull_d', 'policy_code', 'disbursement_method', 'debt_settlement_flag',  'application_type', 'last_pymnt_d', 'last_pymnt_amnt',  'emp_length', 'delinq_2yrs','inq_last_6mths','mths_since_last_delinq','pub_rec','revol_bal',
'revol_util','total_acc','acc_now_delinq','tot_coll_amt','tot_cur_bal','total_rev_hi_lim','acc_open_past_24mths','avg_cur_bal','bc_open_to_buy','bc_util','chargeoff_within_12_mths','delinq_amnt','mo_sin_old_il_acct','mo_sin_old_rev_tl_op',
'mo_sin_rcnt_rev_tl_op','mo_sin_rcnt_tl','mort_acc','mths_since_recent_bc','mths_since_recent_inq','num_tl_30dpd','pct_tl_nvr_dlq','percent_bc_gt_75','pub_rec_bankruptcies','num_bc_sats','tax_liens')

#Drop them from the lcdf data-frame
lcdf <- lcdf %>% select(-all_of(varsToRemove)) 

#Drop all the variables with names starting with "hardship" 
lcdf <- lcdf %>% select(-starts_with("hardship"))

#similarly, all variable starting with "settlement"
lcdf <- lcdf %>% select(-starts_with("settlement"))

# Ordering some of the factor variables before plotting ROC
lcdf$grade <- as.ordered(lcdf$grade)
lcdf$sub_grade <- as.ordered(lcdf$sub_grade)
lcdf$loan_amnt <- ordered(lcdf$loan_amnt)
lcdf$loan_status <- factor(lcdf$loan_status, levels = c("Charged Off","Fully Paid"))
lcdf$loan_amnt <- as.numeric(lcdf$loan_amnt)
dim(lcdf)

# For training set 50%
TRNPROP = 0.5  #proportion of examples in the training sample
nr <- nrow(lcdf)
set.seed(999)
trnIndex <- sample(1:nr, size = round(TRNPROP * nr), replace=FALSE)

lcdfTrn <- lcdf[trnIndex, ]
lcdfTst <- lcdf[-trnIndex, ]

```



```{r Question 1 : Data Transformation}

#Needs all data to be numeric -- so we convert categorical (i.e. factor) variables using one-hot encoding 
#We use the dummyVars function in the 'caret' package to convert factor variables to multiple dummy-variables
fdum <- dummyVars ( ~. , data=lcdf %>% select(-loan_status)) 
dxlcdf <- predict ( fdum, lcdf)


# creates a full set of dummy variables rows = rows of lcdf
dylcdf <- class2ind(lcdf$loan_status, drop2nd = FALSE) 
# and then decide which one to keep
fplcdf <- dylcdf [ , 2] # Fully paid as 1

#Training, test subsets
dxlcdfTrn <- dxlcdf[trnIndex,]
fplcdfTrn <- fplcdf[trnIndex]
dxlcdfTst <- dxlcdf[-trnIndex,]
fplcdfTst <- fplcdf[-trnIndex]

#These variables are useful for performance assessment, but should not be used in the model since they cause leakage
dxTrn <- xgb.DMatrix( subset(dxlcdfTrn, select = -c( actualTerm, actualReturn, total_pymnt, annRet, issue_d)), label=fplcdfTrn)
dxTst <- xgb.DMatrix( subset(dxlcdfTst, select = -c( actualTerm, actualReturn, total_pymnt, annRet, issue_d)), label=fplcdfTst)

#we can watch the progress of learning thru performance on these datasets
xgbWatchlist <- list(train = dxTrn, eval = dxTst)

```

```{r Question 1 : Cross validation and experimenting with different  paramters}

#################################Cross validation on different parameters###################################

#use cross-validation on training dataset to determine best model 
xgbParam <- list (
max_depth = 3, eta = 0.1, 
objective = "binary:logistic", 
eval_metric="error", eval_metric = "auc")
xgb_lscv <- xgb.cv( xgbParam, dxTrn, nrounds = 500, nfold=5, early_stopping_rounds = 10 )
#best iteration
xgb_lscv$best_iteration
xgb_lscv$evaluation_log
#for the best iteration based on performance measure (among those specified in xgbParam)
best_cvIter <- which.max ( xgb_lscv$evaluation_log$test_auc_mean)
#learn the best model without xval
xgb_lsbest <- xgb.train( xgbParam, dxTrn, nrounds = xgb_lscv$best_iteration )
#variable importance
xgb.importance(model = xgb_lsbest) %>% view()


# Runnning cross validation on the different paramters
#paramter list
xgbParam <- list (
objective = "binary:logistic", 
eval_metric="error", eval_metric = "auc")

#with max_depth 6 and eta = 0.1
xgb_lscv <- xgb.cv( xgbParam, dxTrn, nrounds = 500, nfold=5, early_stopping_rounds = 10, max_depth = 6, eta = 0.1 )
#best iteration
xgb_lscv$best_iteration
xgb_lscv$evaluation_log
#for the best iteration based on performance measure (among those specified in xgbParam)
best_cvIter <- which.max (xgb_lscv$evaluation_log$test_auc_mean)
xgb_lscv$evaluation_log[which.max (xgb_lscv$evaluation_log$test_auc_mean)]

# with max_depth 5 and eta 0.01
xgb_lscv1 <- xgb.cv( xgbParam, dxTrn, nrounds = 500, nfold=5, early_stopping_rounds = 10, max_depth = 5, eta = 0.01 )
best_cvIter1 <- which.max (xgb_lscv1$evaluation_log$test_auc_mean)
xgb_lscv1$evaluation_log[which.max (xgb_lscv1$evaluation_log$test_auc_mean)]

# with max_depth 6 and eta 0.1
xgb_lscv2 <- xgb.cv( xgbParam, dxTrn, nrounds = 500, nfold=5, early_stopping_rounds = 10, max_depth = 6, eta = 0.1, min_child_weight=1 )
best_cvIter2 <- which.max (xgb_lscv2$evaluation_log$test_auc_mean)
xgb_lscv2$evaluation_log[which.max (xgb_lscv2$evaluation_log$test_auc_mean)]

# with max_depth 6 and eta 0.1 and min chile weight as 1
xgb_lscv3 <- xgb.cv( xgbParam, dxTrn, nrounds = 50, nfold=5, early_stopping_rounds = 10, max_depth = 6, eta = 0.1, min_child_weight=1 )
best_cvIter3 <- which.max (xgb_lscv3$evaluation_log$test_auc_mean)
xgb_lscv3$evaluation_log[which.max (xgb_lscv3$evaluation_log$test_auc_mean)]


#with evaluation metric as auc. iteration with max eval-auc returned as best iteration
#paramter list
xgbParam <- list (
max_depth = 4, 
objective = "binary:logistic", 
eval_metric="error", eval_metric = "auc")
# with max_depth as 4 and eta = 1
xgb_lsM1 <- xgb.train( xgbParam, dxTrn, nrounds = 500, xgbWatchlist, early_stopping_rounds = 10, eta=1 )


# with evaluation metric as error. iteration with min eval-error returned as best iteration
#paramter list
xgbParam <- list (
 max_depth = 4,
 objective = "binary:logistic", 
 eval_metric="auc", eval_metric = "error")
#with eta as 1
xgb_lsM1 <- xgb.train( xgbParam, dxTrn, nrounds = 500,  xgbWatchlist, early_stopping_rounds = 10, eta=1 )
  # eval error decreased and eval auc decreased 
#with eta as 0.5
xgb_lsM1 <- xgb.train( xgbParam, dxTrn, nrounds = 500, xgbWatchlist, early_stopping_rounds = 10, eta=0.5 )
  # with same parameters but only decreased eta (=0.5), we get good auc value and same error
# with eta as 0.1
xgb_lsM1 <- xgb.train( xgbParam, dxTrn, nrounds = 500, xgbWatchlist, early_stopping_rounds = 10, eta=0.1 )
#with  eta as 0.01
xgb_lsM1 <- xgb.train( xgbParam, dxTrn, nrounds = 500, xgbWatchlist, early_stopping_rounds = 10, eta=0.01 )


#paramter list
xgbParam <- list (
objective = "binary:logistic", 
eval_metric="error", eval_metric = "auc")
#with max depth as 6 and eta as 0.1
xgb_lsM1 <- xgb.train( xgbParam, dxTrn, nrounds = 500, xgbWatchlist, early_stopping_rounds = 10, eta=0.1,   max_depth = 6)
#with max depth as 6 and eta 0.01
xgb_lsM1 <- xgb.train( xgbParam, dxTrn, nrounds = 1000, xgbWatchlist, early_stopping_rounds = 10, eta=0.01, max_depth=6 )
#auc decreased
#with max depth 6, eta 0.1 and lambda 0.05
xgb_lsM1 <- xgb.train( xgbParam, dxTrn, nrounds = 1000, xgbWatchlist, early_stopping_rounds = 10, eta=0.1, max_depth=6, lambda=0.05 )
#with max depth 6, eta 0.1 and lambda 0.05 Col sample by tree 0.5 and subsample = 0.7
xgb_lsM1 <- xgb.train( xgbParam, dxTrn, nrounds = 1000, xgbWatchlist, early_stopping_rounds = 10, eta=0.1, max_depth=6, lambda=0.05, subsample=0.7, colsample_bytree=0.5 )
#Checking of the same sample and colsampleby tree worked with eta = 0.01 and gamma and min child weight as 1
xgb_lsM1 <- xgb.train( xgbParam, dxTrn, nrounds = 1000, xgbWatchlist, early_stopping_rounds= 10, eta=0.01, max_depth=6, lambda=0.05,subsample=0.7, colsample_bytree=0.5, min_child_weight =1 , gamma= 1 )


#paramter list changed the evaluation metric
xgbParam <- list (
objective = "binary:logistic", 
eval_metric="auc", eval_metric = "error")
#Checking for the same set of paramters as before but with different evaluation metric
xgb_lsM1 <- xgb.train( xgbParam, dxTrn, nrounds = 1000, xgbWatchlist, early_stopping_rounds= 10, eta=0.01, max_depth=6, lambda=0.05,subsample=0.7, colsample_bytree=0.5, min_child_weight =1 , gamma= 1 )


### Using hyper parameter to find the best set of parameters ###

# hyper parameters
xgbParamGrid <- expand.grid(
max_depth = c(4, 5, 6),
eta = c(0.01, 0.001, 0.1) )

for(i in 1:nrow(xgbParamGrid)) {
xgb_tune <- xgboost(data=dxTrn, objective = "binary:logistic", nrounds=50, eta=xgbParamGrid$eta[i], 
max_depth=xgbParamGrid$max_depth[i], early_stopping_rounds = 10, eval_metric = "auc", min_child_weight =1 )
xgbParamGrid$bestTree[i] <- xgb_tune$evaluation_log[xgb_tune$best_iteration]$iter
xgbParamGrid$bestPerf[i] <- xgb_tune$evaluation_log[xgb_tune$best_iteration]$train_auc
}

# to view the parameters for the best perf
xgbParamGrid[which.max(xgbParamGrid$bestPerf),]
xgbParamGrid %>% view()

# based on the above for loop, we get the best parameters which is applied below to get the best model
xgbParams <- list (
  booster = "gbtree",
  objective ="binary:logistic",
  min_child_weight=1,
  eval_metric = "auc",
  eval_metric = "error"
)

#train the model on best set of paramters
xgb_lsM1 <- xgb.train( xgbParams, dxTrn, nrounds = 500, xgbWatchlist, early_stopping_rounds = 10 , max_depth=6, eta=0.1)

#best iteration
xgb_lsM1$best_iteration
# predictions from the results of xgb_lsM1
xpredTrg1<-predict(xgb_lsM1, dxTrn)
head(xpredTrg1)

```


```{r Question1 Check for performance}
  
# Check for performance
#confusion matrix of training data
table(pred=as.numeric(xpredTrg1>0.5), act=fplcdfTrn) #accuracy = 86.13%


xgb_lsM2 <- xgb.train( xgbParams, dxTst, nrounds = 500, xgbWatchlist, early_stopping_rounds = 10 , max_depth=6, eta=0.1)
xpredTst2<-predict(xgb_lsM2, dxTst)
table(pred=as.numeric(xpredTst2>0.5), act=fplcdfTst)

#ROC, AUC performance on test data
xpredTst<-predict(xgb_lsM1, dxTst)
pred_xgb_lsM1=prediction(xpredTst, lcdfTst$loan_status, label.ordering = c ("Charged Off", "Fully Paid"))

aucPerf_xgb_lsM1=performance(pred_xgb_lsM1, "tpr", "fpr")
plot(aucPerf_xgb_lsM1)
abline(a=0, b= 1)

# AUC value
aucPerf_xgb_lsM1 = performance(pred_xgb_lsM1,"auc")
aucPerf_xgb_lsM1@y.values

#lift curves
perfLift_xgb1=performance(pred_xgb_lsM1, "lift", "rpp")
plot(perfLift_xgb1, col="red")

# Cost based performance
#Incorporating profits & costs
lcdf %>% filter(loan_status %in% c("Fully Paid")) %>% summarise( intRate = mean(int_rate) )  
# 11.75
# therefore, we can take the profit value on FP loans = (100+3*11.75) = 135.25 so we take 35 as profit value

# to check the avg interest rate for Charged off loans 
lcdf %>% filter(loan_status %in% c("Charged Off")) %>% summarise( intRate = mean(int_rate) )
# 13.86
# therefore, we can take the profit value on CO loans = (100+3*13.86) = 141.58 so we take 42 as loss value

PROFITVAL <- 35
LOSSVAL <- -42

#performance for XGBoost model
scoreXGB <- predict(xgb_lsM1,dxTst)

#Note- we want to identify those loans with high prob for being FullyPaid
prPerfXGB <- data.frame(scoreXGB)
prPerfXGB <- cbind(prPerfXGB, status=lcdfTst$loan_status)
prPerfXGB <- prPerfXGB[order(-scoreXGB) ,]  #sort in desc order of  prob(fully_paid)
prPerfXGB$profit <- ifelse(prPerfXGB$status == 'Fully Paid', PROFITVAL, LOSSVAL)
prPerfXGB$cumProfit <- cumsum(prPerfXGB$profit)

#what is the max profit for xgBoost model
max( prPerfXGB$cumProfit ) 

prPerfXGB$cumProfit[which.max(prPerfXGB$cumProfit)]

#score for that max profit 
prPerfXGB$scoreXGB[which.max(prPerfXGB$cumProfit)]

```


```{r Question 1 : Comparison with DT, RF and XGB}


#Decision Tree model from Asgnt1
lcDT1 <- rpart(loan_status ~., data=lcdfTrn %>% select(-c('actualTerm', 'actualReturn', 'total_pymnt','annRet', 'issue_d')), method="class", parms = list(split = "information"), control = rpart.control(cp=0.0001, minsplit = 30))

#pruned decision tree
lcDT1p <- prune.rpart(lcDT1, cp = 0.00015) 
printcp(lcDT1p)

#RanDom Forest Modem drom AsgŒt1
rfMo`el2 <-0ranger,loan_stAtus ~., da4a=lcdF‘rn %>%  select(-c('actualTerm' 'actualSeturn', #total_pymnt'<'annRet', 'issue_d')), num.trees†=520, probability = TRUE, min.kde.size = 50, hmportanae='permıtation'!m!x.depth = 15)


#ROC for dmcirion Tree
perfROC_DT=performance(pradiction(predict |cDT1p,lcdfTst, type="prgb"([,2], lcdfTst$loan_status),""tpr", dpr")
#ROC for Random Forest
perfROA_RF=performance(predhctio~(predict(rfMoÙel2,lcdfTst)$predictions[,2], lcdfTst$locN^status,label.ordering=c("Ch`rgÂd Off","Fumly P·ad")) "tpr", "&pr")
#ROC for xgBoost model
xprmtTsT<-predicp(xgb_lsM1, dxTst,type="prob")
pred_xgb_lsM1=p·rformance(trediction(xpredTst,`lcddTst$loa._statu{,label.ordering=c("Charged Off","Ftlly Paid")), "tpr", "fpr")

#ROC graph fnr all 3 models togedher
plot(pÂpfROC_D, col='red')M
plot(perfROC_RF, col='blwe', add=TRUE)
plot(pred_xgb_lsM1, col='green', add=TRUE)
leg%nd*'bottomright', c('Prune$ DecisionTr%e Model', 'RafdomForest Model', 'XGBoost$MÔdel'), ,ty=1, col=c('red', 'blue', 'gbeun'))  


#EUC vulud for DT
predDT=pzediction(predict(lcDT1p,lcdnTct, type5"prob")[,2], lcdfTst$lan_statuS )
aucPervDT=performance(prddDT, "auc")
sprintf("AUC: %f", aucPerfD@y.value3)
# AUC`values for Random Fnrest Model
ccoreTst2 <- predict(rfModel2,lcdfTst)
predRF=prediction(scoreTst2$predictions{, "Full9 Pqid"], lcdfTst$loan_status, label.ordering = c( Chirged Ofr","Fully Paid" ))
aucPerfRFqerformance(0redRF, "auc")
sprintf("AUC: %f", aucRerfRF@y.values)
# AUC values$foz Xgboost model
ucPerf_xÁb]lsM1 = performance(pred_xgb^lsM1,"auc")aucPerfxgb_lsM1By.values
J#lkft curve for tie DT, random foÚest and XGboosu
perfLift_DT=performanCe(prmeigtion(predict(lcDD1p,lcdfTsT,†type="trob")[,"Fully!Paid"], lcdfTst$doan_statusd,labul.ordering=c("Cxarged Off!,"Fully$Pcid")), "lift",†"rPp")
p%rfMifp_RF=performance(preTictiof(predict(rfMo`el2,lc‰fTwt)$predictions[,"Fu,Ïy Paid"],lcdfTrt&loan_staÙus,label.krdering5c8"Charged Onf","Fully Paid")), "hift", "rXp")
pervLIvt_XGB=parformancÂ(predictinn(xprmdTst, lcdfTst$,oan_statts,label.oreering=c(¢Cha2ged Off"."Fully @aid"i), b|ift", "rpp")

#Coiparing Lift Curves of three  models
plot(perfLift_DT, col="red")
plot®perfLift_RF, add=RUE, col="blue")plot(perfLift_XGB, e`e=TUE,$col="greenb)
legend('bottomright', c('Pruned Deci{imnTree Model', 'RandomForesp Model', 'HGBoost Model'), lty=1, col=c('red', 'blue',$ßgreen'))


#PerformancÂ for Random Forest
scoreRF º- predicd(rfModel2,lcdfTst, type="responsÂ")$predicTions [,2Nully Pait"]
prPerdJF <- data.frame(scoreRF)
ppPerfRF <-†"bind(prPerfRF, status=lcdfTst$loan_Status)
pzPeznRF <- prTebfRF[order(-scoreRNÈ ,]  #sort in desc†rder of  prob(fully_paid)
pr@erfRF$prmf)t <- ifelse(prPerfRF$status == 'Fully!Paid', PROFI\VAL, LOSSVAM)
prPerfRF$cumProfit <- cumsum(prPerfRF$profit)
max(qrPerfRF$cumProfit)

#Performa.ce for Decision Tree model
screDT <- predict(n#DT1p,lcdfTqt, type="prob¢) [,"Fully Paid"]  
prPerf <- tata.frame(skorÂDT)
prPorf <- cbind(prPerf, status-lkdfTst$loanstatus)
prPerf <- prPerf[order(-scoreDT) ,]  #sort in daSk order oe  pbob(fully_paid)
`rPerf$prvit <- ivelse(prPerf$status == 'Fully Paid', PROFITVAL, LOSSTAL)
prPesf$cumProfit <- cuesum(prPerf$profit)
max(qrPepÊ$cumProfit)	

#Comqarison of profit aurves for DT, Random Forest and XGBoosÙplot(prPerfRF$cumProfit,col=ßblue',lwD = 0.5)
lines(pbPerf$cumProfiT,col='redá,lwd = 0.5)
lines®prPerfXGB$cumProfit, col='green',lwd = 0.5)
legen‰'bottomright', c('cum provip rF','cum profit DT', 'Cqm profit XGB'),†lty=3, col=c('blue+,'red', 'Áreen'))
ç```


`h`{r Que{tion 1 : Decile Lift$Rgrformajke for XG¬ model}

#decile lift perfovmince
# " the 'score' parametgr should give 'prob' of loan_status ==0'charged Off'
fnDecileLifpsPerformance]defaults  <- function( scores, dat) {  #sckre is foP loan_staÙus=='Charged Off',
  totDefRate= sum(dat$loAn_status=="Ch·rged Off")/nrow(dati
 "decPerv <- data.freme(scores)
  decTevf <- cb)nd(decPerf, sdatus=dat$loan_3latus, grade=dAt$gra$e)
  de„PErf <- d%cPerf %>% eutate(deckle = ntile(-scores, 10))
  decPerf<-  decPerf  %4% group_by)decile) %>% summarise ( 
    c/unt=n(	, numDefaults=sum(staTuÒ=="Charged Off¢) defaultRate=numDdfaultsocount,
    topA=sum(grade=="A"),totB=sum(gzade=="B" ), tnt=sum(grade==¢C"), totD=sum(grade="D"),-
    totE=sum(gÚade=="E"),touF=sUm('2ade=="F") ( totG=sum(grade=='G'))
† decQerf$„umDefaults=cemsum(decPe2f$numDefaults)                      M
  decPerf,cumDefaultRate=decPerf$cumDefaultS/cumsum(dec@erf$count)   !                 )
  decPeRf$cumDefaeltLift<- decPerf$cumDefaultRate/(sum(decPerf$ÓumDefaults)/sem(decPerf$count))
    pr)nv(dekPerf)
}


#Smturns performance by deciles
fnDecileRet5rnsPerformance <-`function( 3cores, dat) {
  dgcReuPerd <- data.f2ame(scoresi
  decRetPerf <- c"ind(decRetPerf, statuÛ=dat$locn_status, gradeΩdat$grade$ aCtRet=d·t$actualRetur., actTerm 9`dat$acÙ=alTgrm)
  decRetPerf <- decRetPerf %>% mutate(de„ile = nti,e(-scores, q0))
  decRetPepf %>% group_by(decile) %>% summarise (
 `  count=n(), n}mDefaults=sum(status=="Cjarged Off"), avgAcvBmt=mean(actRet), miHRet=min(a#tRet), ma8Ret=max(actRet),
    avgTer=mean(actTa2m), totA=sum(grade<="A"), totF=sum(grad-=="B" ), totC=sum(Grade=="C"),0totD=sul(grade=="d")l
    totE=sum(grade=="E"-,0totV=sum,grade=="F"),totG=s}m(grade=='«') )
}


#decil‰ laft rErformance by defaults
scoreXGB <-`predict(xgb_lsM1¨exTst)
fnDecileLiftsPerformance_defaults( ppedict)xgb_lsM1, dpTst), lcdf\st  )"
# Returns performancm by decile
vnDecyleReturn3Performan„e( predict(xgb_lsM1, dxTwt, type="responsm ), lcdfT3t  ) #on test data

```


```{r question 2a}
#levels fro loan status
leve|s(lcdd‘rn$loan_sta4us)
#encod}d tjd $ependent var here to make sure that q is for "Fqlly Paid"
yTrn<-faktor(if_else(lcdFTrn$loan_status=="Fully Paid", '1', '0') )ç!predictor variable
xDTrn<-lcdfTrn %>% select(-loan_status, -actualTerm, -actu`lReturn, -total_pymnt, -annRet, -issue_d)

# cross valid`tion on generalized linear modml 
# famkly: ‚Äúbinomial‚Äù†"/2 a ‚inary dependant variable


#Mg`el 1 with defaultsM
flmls_cv <- cv.glmbet(data.matrix(xDTrn), yTrn, Êamily="bioomial")
# lamba min : minimizes out-of-sample loss in CV
elmls_cv$limbda.min
# The Œª1se is thm one which is the |crgest Œª valug wathin 1 standard error$f Œªmin.
glmls_cvdlcebda.1sg
plot(glmhs_c6©
#The ver4i#am lines show the loaations of ŒªMin an$ Œª1se
#ThÂ numbers(across thg top are tle number of nmnzero boefficient"estimatÂs
#coefficients(velues for thg variabley
as.ma|rix(coef(glmls_cv, s = glmls_cv$lambda.min))
as.matrix(cogf(glMls_cv, s = glmlsGcv$lambda1se))
glmls_cv$glmneÙ.fit
#lf: # varaables in the model'%dev8 the percent (of null) `eviance explaifEd 
#So, as the extent of regulari˚Ation (lamjda) decreasEs, we‚Äôd expect the %Dev Ùo increa⁄q
#Indeh to the laÌbla.1se value
which(glmls_kv&lambdi == flmls_cv$lambda.1se)ç
#The dev.ratio corresponding to the lamf`a.1se val5e
#dev.ratio = 1mdeviance?nulldev
glmls_cv$glmnet.fit$dev.ratio[wxich(glmls_cv,lambda"== glmlsOcv$lambda.1se) ]
#graphs for!the default mode, 1
p|ot(glmlc_cv$glmnet.&iti
plot(glmls_cw$glmnetnfIt, xvar= &lambdc")
`dot(glmls_cv$glenep.fct, xvAr= "dev")
#predictaons for the cv model (Model 1 with defaults)
glmls_cv_pred=xredict ( elmls_cv,d!va.matrix(xDTrn), s="lambda.min",  type="response"! )
predsau·_cv <-!prediction(wlmls]cv_pred, lcdfVrn$,oan_status, label.ordering = c("Charged ff", "Fully Paid"))M
auc–$rf_cv <-"performance(predsauc[cv, "auc")
aucParf_cv@y.values

à#Model 2 with typm.measuru = auc# cross validation with type.measure = auc *  gifes area under the`ROC curve
glmls_cv_auc<- cv.glmnet(dapa.oatrix(xLîrn),0yTrn, family=2bÈoomial" typenmeaÛure = "auc")
plov(glmlq_cv_auc)
glmls_cv_auc$lambda.-in
glmls_cf_auc$lambda.1se
# the cvoss-vanidation 'Ïoss' at each lambda
olmls_cv_auc$cvm
+to get the 'loss' vqlue at lambde == laMbda.1se
glmls_cv_auc$cvm [ which(glmls_cv_auc$lambda == glmls_cv_auc$lambda.1se) ]
"predictions
glels_cv_auc_pred=predict ( glmls]cv_auc.data.matrix(xDTrn), s="lambda.min",  type="response"  )
predsauc_auc <- prediction(glmls_cv_auc_pred, lcdfTrn$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_auc <- performance(predsauc_auc, "auc")
aucPerf_auc@y.values
# The AUC value for the model1 and 2 is almost the same for lambda.min

# the cross-validation 'loss' at each lambda
glmls_cv_auc$cvm [ which(glmls_cv_auc$lambda == glmls_cv_auc$lambda.min) ]
glmls_cv$cvm [ which(glmls_cv$lambda == glmls_cv$lambda.min) ]
# When comparing the loss at each lambda's minimum value, we get less loss with model 1


#Model 3 with weights
# for a more balanced data
sum(yTrn == 0)
#[1] 7641
sum(yTrn == 1)
#[1] 47331
1-sum(yTrn==0)/length(yTrn)
# [1] 0.861
1-sum(yTrn==1)/length(yTrn)
#[1] 0.139
wts = if_else(yTrn==0,1-sum(yTrn==0)/length(yTrn), 1-sum(yTrn==1)/length(yTrn))
# cv model with wts 
glmls_cv_w <- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial", weights = wts, type.measure="deviance")
plot(glmls_cv_w)
# the lambda min 
glmls_cv_w$lambda.min
glmls_cv_w$lambda.1se
#coefficients for models with weight
as.matrix(coef(glmls_cv_w, s = glmls_cv_w$lambda.min))
#for model without weights
as.matrix(coef(glmls_cv, s = glmls_cv$lambda.min))
#intercept and other values are less for model with weights
# the lambda minimum value of the model without weights is less than than with weights
#predictions fro the Model 3 with weights
glmls_cvw_pred = predict ( glmls_cv_w,data.matrix(xDTrn), s="lambda.min",  type="response"  )
predsauc_cv_w <- prediction(glmls_cvw_pred, lcdfTrn$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_cv_w <- performance(predsauc_cv_w, "auc")
aucPerf_cv_w@y.values
#The auc value for Model 1, 2 and 3 seems the same
# the cross-validation 'loss' at each lambda
glmls_cv_w$cvm [ which(glmls_cv_w$lambda == glmls_cv_w$lambda.min) ]
# the cross validation loss seems to be the min for model 3 with weights. 


#Model 4 with ridge regression (L2 regularization) : to minimize the complexity of the model 
#adding a penalty parameter that is equivalent to the square of the magnitude of the coefficients.
glmls_cv_ridge <- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure="deviance", alpha = 0)
plot(glmls_cv_ridge)
glmls_cv_ridge$lambda.min
glmls_cv_ridge$lambda.1se
#coefficients for ridge regression
as.matrix(coef(glmls_cv_ridge, s = glmls_cv_ridge$lambda.min))
#predictions fro the Model 4
glmls_cv_ridge_pred = predict ( glmls_cv_ridge,data.matrix(xDTrn), s="lambda.min",  type="response"  )
predsauc_cv_ridge <- prediction(glmls_cv_ridge_pred, lcdfTrn$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_cv_ridge <- performance(predsauc_cv_ridge, "auc")
aucPerf_cv_ridge@y.values
# the cross-validation 'loss' at each lambda
glmls_cv_ridge$cvm [ which(glmls_cv_ridge$lambda == glmls_cv_ridge$lambda.min) ]


#Model 5 with lasso regression : (Least Absolute Shrinkage and Selection Operator) : to minimize the complexity of the model by limiting the sum of the absolute values of the model coefficients (L1 regularization)
#sets coefficients to zero, thus eliminates non-useful variables
glmls_cv_lasso <- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure="deviance", alpha = 1)
plot(glmls_cv_lasso)
glmls_cv_lasso$lambda.min
glmls_cv_lasso$lambda.1se
#coefficients for ridge regression
as.matrix(coef(glmls_cv_lasso, s = glmls_cv_lasso$lambda.min))
#predictions fro the cv model (Model 3 with weights)
glmls_cv_lasso_pred = predict ( glmls_cv_lasso,data.matrix(xDTrn), s="lambda.min",  type="response"  )
predsauc_cv_lasso <- prediction(glmls_cv_lasso_pred, lcdfTrn$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_cv_lasso <- performance(predsauc_cv_lasso, "auc")
aucPerf_cv_lasso@y.values
# the cross-validation 'loss' at each lambda
glmls_cv_lasso$cvm [ which(glmls_cv_lasso$lambda == glmls_cv_lasso$lambda.min) ]


# table of lambda values for all models
lambda_values <- data.frame(Model1_Default = glmls_cv$lambda.min,
            Model2_AUC = glmls_cv_auc$lambda.min, 
            Model3_weight = glmls_cv_w$lambda.min, 
            Model4_ridge = glmls_cv_ridge$lambda.min,
            Model5_lasso = glmls_cv_lasso$lambda.min,
             stringsAsFactors = FALSE)
lambda_values
# finding the min lambda value
which.min(lambda_values)

# table of cross-validation 'loss' at each lambda for all models
cvm_values <- data.frame(Model1_Default = glmls_cv$cvm[which(glmls_cv$lambda == glmls_cv$lambda.min)],
            Model2_AUC = glmls_cv_auc$cvm[which(glmls_cv_auc$lambda == glmls_cv_auc$lambda.min)], 
            Model3_weight = glmls_cv_w$cvm[which(glmls_cv_w$lambda == glmls_cv_w$lambda.min)], 
            Model4_ridge = glmls_cv_ridge$cvm[which(glmls_cv_ridge$lambda == glmls_cv_ridge$lambda.min)],
            Model5_lasso = glmls_cv_lasso$cvm[which(glmls_cv_lasso$lambda == glmls_cv_lasso$lambda.min)],
             stringsAsFactors = FALSE)
cvm_values
# finding the min lambda value
which.min(cvm_values)


#levels fro test data set
levels(lcdfTst$loan_status)
#encoded the dependent var here to make sure that 1 is for "Fully Paid" for test data
yTst<-factor(if_else(lcdfTst$loan_status=="Fully Paid", '1', '0') )
#predictor variable
xDTst<-lcdfTst %>% select(-loan_status, -actualTerm, -actualReturn, -total_pymnt, -annRet, -issue_d)
# fitting a generalized linear model with the best parameters
glmls_1 <- glmnet(data.matrix(xDTst), yTst, family="binomial", type.measure="deviance", alpha = 1,
                  lambda = glmls_cv_lasso$lambda.min )
#coefficients from the cross validation and new best model
as.matrix(coef(glmls_cv_lasso, s = glmls_cv_lasso$lambda.min))
as.matrix(coef(glmls_1, s = glmls_1$lambda.min))
# If we check for the lambda values for both, we get almost similar values
#predictions on Test data
glmls_Tst_pred = predict ( glmls_1,data.matrix(xDTst), s="lambda.min",  type="response"  )
predsauc_2 <- prediction(glmls_Tst_pred, lcdfTst$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_2 <- performance(predsauc_2, "auc")
aucPerf_2@y.values
glmls_1$lambda
#Coefficients from the glmnet lasso model
as.matrix( coef(glmls_1, s= glmls_1$lambda.min))


# now that we have the best set of variables from lasso, we use them without regularization
#get the names of variables with non-zero coefficients from the regularized model 
nzCoef <- as.matrix( coef(glmls_1, s= glmls_1$lambda.min))
nzCoefVars <- nzCoef[-1,1]
names(nzCoefVars)
# fitting a generalized linear model with no regularization
glmls_nzv_2 <- glm(yTst ~ data.matrix(xDTst %>% select(names(nzCoefVars))), family=binomial())
summary(glmls_nzv_2)
plot(glmls_nzv_2)


# Plots for all models
plot(glmls_cv$glmnet.fit)
plot(glmls_cv$glmnet.fit, xvar= "lambda")
plot(glmls_cv$glmnet.fit, xvar= "dev")

plot(glmls_cv_auc$glmnet.fit)
plot(glmls_cv_auc$glmnet.fit, xvar= "lambda")
plot(glmls_cv_auc$glmnet.fit, xvar= "dev")

plot(glmls_cv_w$glmnet.fit)
plot(glmls_cv_w$glmnet.fit, xvar= "lambda")
plot(glmls_cv_w$glmnet.fit, xvar= "dev")

plot(glmls_cv_ridge$glmnet.fit)
plot(glmls_cv_ridge$glmnet.fit, xvar= "lambda")
plot(glmls_cv_ridge$glmnet.fit, xvar= "dev")

plot(glmls_cv_lasso$glmnet.fit)
plot(glmls_cv_lasso$glmnet.fit, xvar= "lambda")
plot(glmls_cv_lasso$glmnet.fit, xvar= "dev")


```


```{r Question 2c}

#confusion_matrix for best glm model on Trn data
glmls_lasso_pred <- predict(glmls_1, data.matrix(xDTrn),s=glmls_1$lambda.1se,type="class")
glmls_lasso_pred <- factor(glmls_lasso_pred, levels=c(1,0))
yD2 <- factor(yTrn, levels=c(1,0))                         
caret::confusionMatrix(glmls_lasso_pred,yD2, positive="1") 

#confusion_matrix for best glm model on Lasso Model
glmls_lasso_pred <- predict(glmls_1, data.matrix(xDTst),s=glmls_1$lambda.1se,type="class")
glmls_lasso_pred <- factor(glmls_lasso_pred, levels=c(1,0))
yD2 <- factor(yTst, levels=c(1,0))                         
caret::confusionMatrix(glmls_lasso_pred,yD2, positive="1") 


# Ridge regression Model
glm_ridge <- glmnet(data.matrix(xDTst), yTst, family="binomial", type.measure="deviance", alpha = 0,
                  lambda = glmls_cv_ridge$lambda.min )

#predictions for ridge on test data
glm_ridge_pred = predict ( glm_ridge,data.matrix(xDTst), s="lambda.min",  type="response"  )
predsauc_ridge <- prediction(glm_ridge_pred, lcdfTst$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_ridge <- performance(predsauc_ridge, "auc")
aucPerf_ridge@y.values

#confusion_matrix for Ridge Model
glm_ridge_pred <- predict(glm_ridge, data.matrix(xDTst),s=glm_ridge$lambda.1se,type="class")
glm_ridge_pred <- factor(glm_ridge_pred, levels=c(1,0))
yD2 <- factor(yTst, levels=c(1,0))                         
caret::confusionMatrix (glm_ridge_pred,yD2, positive="1")

#Performance for Random Forest
scoreRF <- predict(rfModel2,lcdfTst)$predictions
scoreRF = ifelse(scoreRF[, "Fully Paid"] >= 0.5, 1, 0)
scoreRF <- factor(scoreRF, levels=c(1,0))
yD2 <- factor(yTst, levels=c(1,0))  
caret::confusionMatrix(scoreRF,yD2, positive="1")

```

```{r Question 2d}

# we are using the library vip(variable importance plots) to check for the variables importance
#for Lasso regression model
tbl_lasso <- vi_model(glmls_1)
arrange(tbl_lasso,desc(Importance),Variable)%>% view()
# num_tl_120dpd_2m

#For Ridge Regression model
tbl_ridge <- vi_model(glm_ridge)
arrange(tbl_ridge,desc(Importance),Variable)%>% view()
# num_tl_120dpd_2m

#For Random Forest
tbl_rf <- vi_model(rfModel2)
arrange(tbl_rf,desc(Importance),Variable)%>% view()
#installment

# For XGBoost Model
tbl_xgb <- vi_model(xgb_lsM1)
arrange(tbl_xgb,desc(Importance),Variable)%>% view()
# subgrade

# For Decision Tree Model
tbl_dtp <- vi_model(lcDT1p)
arrange(tbl_dtp,desc(Importance),Variable)%>% view()
# subgrade

```


```{r Question 2e}
# Balancing the training data - with over- and under-sampling

# Split data into training, test subsets, balance the training data
nr<-nrow(lcdf)
set.seed(999)
trnIndex = sample(1:nr, size = round(0.7*nr), replace=FALSE) 
lcdfTrn <- lcdf[trnIndex, ] 
lcdfTst <- lcdf[-trnIndex, ]
dim(lcdfTst)
dim(lcdfTrn)


#undersampling of the training data
us_lcdfTrn <-ovun.sample(loan_status~., data = as.data.frame(lcdfTrn), na.action = na.pass, method="under", p=0.5)$data
us_lcdfTrn %>% group_by(loan_status) %>% count()
dim(lcdfTrn)
dim(us_lcdfTrn)
#undersampling of test data
us_lcdfTst <-ovun.sample(loan_status~., data = as.data.frame(lcdfTst), na.action = na.pass, method="under", p=0.5)$data
us_lcdfTst %>% group_by(loan_status) %>% count()
dim(lcdfTst)
dim(us_lcdfTst)

#oversampling of training data
os_lcdfTrn<-ovun.sample(loan_status~., data = as.data.frame(lcdfTrn), na.action = na.pass, method="over", p=0.5)$data
os_lcdfTrn %>% group_by(loan_status) %>% count()
dim(lcdfTrn)
dim(os_lcdfTrn)
#oversampling of test data
os_lcdfTst <-ovun.sample(loan_status~., data = as.data.frame(lcdfTst), na.action = na.pass, method="over", p=0.5)$data
os_lcdfTst %>% group_by(loan_status) %>% count()
dim(lcdfTst)
dim(os_lcdfTst)

#both oversampling and undersampling of training data
bs_lcdfTrn<-ovun.sample(loan_status~., data = as.data.frame(lcdfTrn), na.action = na.pass, method="both", p=0.5)$data
bs_lcdfTrn %>% group_by(loan_status) %>% count()
dim(lcdfTrn)
dim(bs_lcdfTrn)
#both oversampling and undersampling of test data
bs_lcdfTst<-ovun.sample(loan_status~., data = as.data.frame(lcdfTst), na.action = na.pass, method="both", p=0.5)$data
bs_lcdfTst %>% group_by(loan_status) %>% count()
dim(lcdfTst)
dim(bs_lcdfTst)



### LASSO REGRESSION ###
### Lasso Regression with Undersampling on Training data
yTrn<-factor(if_else(us_lcdfTrn$loan_status=="Fully Paid", '1', '0') )
xDTrn<-us_lcdfTrn %>% select(-loan_status, -actualTerm, -actualReturn, -total_pymnt, -annRet, -issue_d)
#CV to find the lambda.min
glmls_cv_us_trn <- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure="deviance", alpha = 1)
# fitting a generalized linear model
glmls_us_trn <- glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure="deviance", alpha = 1,
                  lambda = glmls_cv_us_trn$lambda.min )
#predictions 
glmls_us_trn_pred = predict ( glmls_us_trn,data.matrix(xDTrn), s="lambda.min",  type="response"  )
predsauc_ls_us_trn <- prediction(glmls_us_trn_pred, us_lcdfTrn$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_ls_us_trn <- performance(predsauc_ls_us_trn, "auc")
aucPerf_ls_us_trn@y.values

### Lasso Regression with Undersampling on Test data
yTst<-factor(if_else(us_lcdfTst$loan_status=="Fully Paid", '1', '0') )
xDTst<-us_lcdfTst %>% select(-loan_status, -actualTerm, -actualReturn, -total_pymnt, -annRet, -issue_d)
#CV to find the lambda.min
glmls_cv_us_tst <- cv.glmnet(data.matrix(xDTst), yTst, family="binomial", type.measure="deviance", alpha = 1)
# fitting a generalized linear model
glmls_us_tst <- glmnet(data.matrix(xDTst), yTst, family="binomial", type.measure="deviance", alpha = 1,
                  lambda = glmls_cv_us_tst$lambda.min )
#predictions 
glmls_us_tst_pred = predict ( glmls_us_tst,data.matrix(xDTst), s="lambda.min",  type="response"  )
predsauc_ls_us_tst <- prediction(glmls_us_tst_pred, us_lcdfTst$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_ls_us_tst <- performance(predsauc_ls_us_tst, "auc")
aucPerf_ls_us_tst@y.values


### Lasso Regression with Oversampling on Training data
yTrn<-factor(if_else(os_lcdfTrn$loan_status=="Fully Paid", '1', '0') )
xDTrn<-os_lcdfTrn %>% select(-loan_status, -actualTerm, -actualReturn, -total_pymnt, -annRet, -issue_d)
#CV to find the lambda.min
glmls_cv_os_trn <- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure="deviance", alpha = 1)
# fitting a generalized linear model
glmls_os_trn <- glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure="deviance", alpha = 1,
                  lambda = glmls_cv_os_trn$lambda.min )
#predictions 
glmls_os_trn_pred = predict ( glmls_os_trn,data.matrix(xDTrn), s="lambda.min",  type="response"  )
predsauc_ls_os_trn <- prediction(glmls_os_trn_pred, os_lcdfTrn$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_ls_os_trn <- performance(predsauc_ls_os_trn, "auc")
aucPerf_ls_os_trn@y.values

### Lasso Regression with Oversampling on Test data
yTst<-factor(if_else(os_lcdfTst$loan_status=="Fully Paid", '1', '0') )
xDTst<-os_lcdfTst %>% select(-loan_status, -actualTerm, -actualReturn, -total_pymnt, -annRet, -issue_d)
#CV to find the lambda.min
glmls_cv_os_tst <- cv.glmnet(data.matrix(xDTst), yTst, family="binomial", type.measure="deviance", alpha = 1)
# fitting a generalized linear model
glmls_os_tst <- glmnet(data.matrix(xDTst), yTst, family="binomial", type.measure="deviance", alpha = 1,
                  lambda = glmls_cv_os_tst$lambda.min )
#predictions 
glmls_os_tst_pred = predict ( glmls_os_tst,data.matrix(xDTst), s="lambda.min",  type="response"  )
predsauc_ls_os_tst <- prediction(glmls_os_tst_pred, os_lcdfTst$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_ls_os_tst <- performance(predsauc_ls_os_tst, "auc")
aucPerf_ls_os_tst@y.values


### Lasso Regression with both Oversampling and Undersampling on Training data
yTrn<-factor(if_else(bs_lcdfTrn$loan_status=="Fully Paid", '1', '0') )
xDTrn<-bs_lcdfTrn %>% select(-loan_status, -actualTerm, -actualReturn, -total_pymnt, -annRet, -issue_d)
#CV to find the lambda.min
glmls_cv_bs_trn <- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure="deviance", alpha = 1)
# fitting a generalized linear model
glmls_bs_trn <- glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure="deviance", alpha = 1,
                  lambda = glmls_cv_bs_trn$lambda.min )
#predictions 
glmls_bs_trn_pred = predict ( glmls_bs_trn,data.matrix(xDTrn), s="lambda.min",  type="response"  )
predsauc_ls_bs_trn <- prediction(glmls_bs_trn_pred, bs_lcdfTrn$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_ls_bs_trn <- performance(predsauc_ls_bs_trn, "auc")
aucPerf_ls_bs_trn@y.values

### Lasso Regression with Oversampling on Test data
yTst<-factor(if_else(bs_lcdfTst$loan_status=="Fully Paid", '1', '0') )
xDTst<-bs_lcdfTst %>% select(-loan_status, -actualTerm, -actualReturn, -total_pymnt, -annRet, -issue_d)
#CV to find the lambda.min
glmls_cv_bs_tst <- cv.glmnet(data.matrix(xDTst), yTst, family="binomial", type.measure="deviance", alpha = 1)
# fitting a generalized linear model
glmls_bs_tst <- glmnet(data.matrix(xDTst), yTst, family="binomial", type.measure="deviance", alpha = 1,
                  lambda = glmls_cv_bs_tst$lambda.min )
#predictions 
glmls_bs_tst_pred = predict ( glmls_bs_tst,data.matrix(xDTst), s="lambda.min",  type="response"  )
predsauc_ls_bs_tst <- prediction(glmls_bs_tst_pred, bs_lcdfTst$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_ls_bs_tst <- performance(predsauc_ls_bs_tst, "auc")
aucPerf_ls_bs_tst@y.values



### RIDGE REGRESSION ###
### Ridge Regression with Undersampling on Training data
yTrn<-factor(if_else(us_lcdfTrn$loan_status=="Fully Paid", '1', '0') )
xDTrn<-us_lcdfTrn %>% select(-loan_status, -actualTerm, -actualReturn, -total_pymnt, -annRet, -issue_d)
#CV to find the lambda.min
glm_cv_us_trn <- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure="deviance", alpha = 0)
# fitting a generalized linear model
glm_us_trn <- glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure="deviance", alpha = 0,
                  lambda = glm_cv_us_trn$lambda.min )
#predictions 
glm_us_trn_pred = predict ( glm_us_trn,data.matrix(xDTrn), s="lambda.min",  type="response"  )
predsauc_us_trn <- prediction(glm_us_trn_pred, us_lcdfTrn$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_us_trn <- performance(predsauc_us_trn, "auc")
aucPerf_us_trn@y.values

### Ridge Regression with Undersampling on Test data
yTst<-factor(if_else(us_lcdfTst$loan_status=="Fully Paid", '1', '0') )
xDTst<-us_lcdfTst %>% select(-loan_status, -actualTerm, -actualReturn, -total_pymnt, -annRet, -issue_d)
#CV to find the lambda.min
glm_cv_us_tst <- cv.glmnet(data.matrix(xDTst), yTst, family="binomial", type.measure="deviance", alpha = 0)
# fitting a generalized linear model
glm_us_tst <- glmnet(data.matrix(xDTst), yTst, family="binomial", type.measure="deviance", alpha = 0,
                  lambda = glm_cv_us_tst$lambda.min )
#predictions 
glm_us_tst_pred = predict ( glm_us_tst,data.matrix(xDTst), s="lambda.min",  type="response"  )
predsauc_us_tst <- prediction(glm_us_tst_pred, us_lcdfTst$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_us_tst <- performance(predsauc_us_tst, "auc")
aucPerf_us_tst@y.values


### Ridge Regression with Oversampling on Training data
yTrn<-factor(if_else(os_lcdfTrn$loan_status=="Fully Paid", '1', '0') )
xDTrn<-os_lcdfTrn %>% select(-loan_status, -actualTerm, -actualReturn, -total_pymnt, -annRet, -issue_d)
#CV to find the lambda.min
glm_cv_os_trn <- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure="deviance", alpha = 0)
# fitting a generalized linear model
glm_os_trn <- glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure="deviance", alpha = 0,
                  lambda = glm_cv_os_trn$lambda.min )
#predictions 
glm_os_trn_pred = predict ( glm_os_trn,data.matrix(xDTrn), s="lambda.min",  type="response"  )
predsauc_os_trn <- prediction(glm_os_trn_pred, os_lcdfTrn$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_os_trn <- performance(predsauc_os_trn, "auc")
aucPerf_os_trn@y.values


### Ridge Regression with Oversampling on Test data
yTst<-factor(if_else(os_lcdfTst$loan_status=="Fully Paid", '1', '0') )
xDTst<-os_lcdfTst %>% select(-loan_status, -actualTerm, -actualReturn, -total_pymnt, -annRet, -issue_d)
#CV to find the lambda.min
glm_cv_os_tst <- cv.glmnet(data.matrix(xDTst), yTst, family="binomial", type.measure="deviance", alpha = 0)
# fitting a generalized linear model
glm_os_tst <- glmnet(data.matrix(xDTst), yTst, family="binomial", type.measure="deviance", alpha = 0,
                  lambda = glm_cv_os_tst$lambda.min )
#predictions 
glm_os_tst_pred = predict ( glm_os_tst,data.matrix(xDTst), s="lambda.min",  type="response"  )
predsauc_os_tst <- prediction(glm_os_tst_pred, os_lcdfTst$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_os_tst <- performance(predsauc_os_tst, "auc")
aucPerf_os_tst@y.values


### Ridge Regression with both Oversampling and Undersampling on Training data
yTrn<-factor(if_else(bs_lcdfTrn$loan_status=="Fully Paid", '1', '0') )
xDTrn<-bs_lcdfTrn %>% select(-loan_status, -actualTerm, -actualReturn, -total_pymnt, -annRet, -issue_d)
#CV to find the lambda.min
glm_cv_bs_trn <- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure="deviance", alpha = 0)
# fitting a generalized linear model
glm_bs_trn <- glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure="deviance", alpha = 0,
                  lambda = glm_cv_bs_trn$lambda.min )
#predictions 
glm_bs_trn_pred = predict ( glm_bs_trn,data.matrix(xDTrn), s="lambda.min",  type="response"  )
predsauc_bs_trn <- prediction(glm_bs_trn_pred, bs_lcdfTrn$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_bs_trn <- performance(predsauc_bs_trn, "auc")
aucPerf_bs_trn@y.values

### Ridge Regression with Oversampling on Test data
yTst<-factor(if_else(bs_lcdfTst$loan_status=="Fully Paid", '1', '0') )
xDTst<-bs_lcdfTst %>% select(-loan_status, -actualTerm, -actualReturn, -total_pymnt, -annRet, -issue_d)
#CV to find the lambda.min
glm_cv_bs_tst <- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure="deviance", alpha = 0)
# fitting a generalized linear model
glm_bs_tst <- glmnet(data.matrix(xDTst), yTst, family="binomial", type.measure="deviance", alpha = 0,
                  lambda = glm_cv_bs_tst$lambda.min )
#predictions 
glm_bs_tst_pred = predict ( glm_bs_tst,data.matrix(xDTst), s="lambda.min",  type="response"  )
predsauc_bs_tst <- prediction(glm_bs_tst_pred, bs_lcdfTst$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerf_bs_tst <- performance(predsauc_bs_tst, "auc")
aucPerf_bs_tst@y.values



###Confusion Matrices###
#Data set for Undersampling
yTst<-factor(if_else(us_lcdfTst$loan_status=="Fully Paid", '1', '0') )
xDTst<-us_lcdfTst %>% select(-loan_status, -actualTerm, -actualReturn, -total_pymnt, -annRet, -issue_d)
#confusion Matrix for undersampling Lasso model
glmls_us_pred <- predict(glmls_us_tst, data.matrix(xDTst),s="lambda.min",type="class")
glmls_us_pred <- factor(glmls_us_pred, levels=c(1,0))
yTst <- factor(yTst, levels=c(1,0))                         
caret::confusionMatrix (glmls_us_pred,yTst, positive="1") 
#confusion Matrix for undersampling Ridge model
glm_us_pred <- predict(glm_us_tst, data.matrix(xDTst),s="lambda.min",type="class")
glm_us_pred <- factor(glm_us_pred, levels=c(1,0))
yTst <- factor(yTst, levels=c(1,0))                         
caret::confusionMatrix (glm_us_pred,yTst, positive="1") 

#Data set for Oversampling
yTst<-factor(if_else(os_lcdfTst$loan_status=="Fully Paid", '1', '0') )
xDTst<-os_lcdfTst %>% select(-loan_status, -actualTerm, -actualReturn, -total_pymnt, -annRet, -issue_d)
#confusion Matrix for oversampling Lasso model
glmls_os_pred <- predict(glmls_os_tst, data.matrix(xDTst),s="lambda.min",type="class")
glmls_os_pred <- factor(glmls_os_pred, levels=c(1,0))
yTst <- factor(yTst, levels=c(1,0))                         
caret::confusionMatrix (glmls_os_pred,yTst, positive="1") 
#confusion Matrix for oversampling Ridge model
glm_os_pred <- predict(glm_os_tst, data.matrix(xDTst),s="lambda.min",type="class")
glm_os_pred <- factor(glm_os_pred, levels=c(1,0))
yTst <- factor(yTst, levels=c(1,0))                         
caret::confusionMatrix (glm_os_pred,yTst, positive="1") 

#Data set for both under and Oversampling
yTst<-factor(if_else(bs_lcdfTst$loan_status=="Fully Paid", '1', '0') )
xDTst<-bs_lcdfTst %>% select(-loan_status, -actualTerm, -actualReturn, -total_pymnt, -annRet, -issue_d)
#confusion Matrix for both under and oversampling Lasso model
glmls_bs_pred <- predict(glmls_bs_tst, data.matrix(xDTst),s="lambda.min",type="class")
glmls_bs_pred <- factor(glmls_bs_pred, levels=c(1,0))
yTst <- factor(yTst, levels=c(1,0))                         
caret::confusionMatrix (glmls_bs_pred,yTst, positive="1") 
#confusion Matrix for both under and oversampling Ridge model
glm_bs_pred <- predict(glm_bs_tst, data.matrix(xDTst),s="lambda.min",type="class")
glm_bs_pred <- factor(glm_bs_pred, levels=c(1,0))
yTst <- factor(yTst, levels=c(1,0))                         
caret::confusionMatrix (glm_bs_pred,yTst, positive="1") 


# Confusion matrix for Lasso model with unbalanced data
yTst<-factor(if_else(lcdfTst$loan_status=="Fully Paid", '1', '0') )
xDTst<-lcdfTst %>% select(-loan_status, -actualTerm, -actualReturn, -total_pymnt, -annRet, -issue_d)
glmls_1 <- glmnet(data.matrix(xDTst), yTst, family="binomial", type.measure="deviance", alpha = 1,
                  lambda = glmls_cv_lasso$lambda.min )
glmls_1_pred <- predict(glmls_1, data.matrix(xDTst),s}"lambda.min",type="class")
glmls_1pred 4- fector8gllls_1_pred, levels=c(1,0))
yTst <- factor(yTsv,0mevelq=c(1,0))    $                    -caret::co~fusionMatrix(glmls_1_pre‰,yUst, positive="1") 
# ConfuSio. matrix &b Ridge model with Unbalancdd data
glm_ridge <- glmnet®dcta.matrix(xDTst). yTct, family="binomial", type.measure="deviance", alpha = 0<
                  la}bda = glmls_cv_ridee$lambda.min )
Gl-_ridge_pred <- prediCt(glm_ridge, data.matryx(xDTst),s="lambda.min",tyre="class")
glm_ridge_pred <- fak|or(glm_2idge_pre$, levelsΩc(1,0))
yTst <- factor(yTst,!hevels=c(1,0-)      "†       †"        
#irgt::confusionMatrix (glm_ridge_pred,yTst, positive="1") 

```
ç
```{r Qumrtmon 3}

#######3####GLM##+#########
# GLM Lasso  model for actuad returns ok tzayning data
# training and test data"sets
xF<-lcdf‘rn %>% selecÙ(-loan_stadusl -actu`lderm, -actualReturn, -totalWpyint, mannRet, -issue‰)
xD_1<lcdfDst"%>% seleÎt(-loan_s`atus, -actualTerm, -ictualReturn, -total_tymnt, -afnRet, -issue_d)

#GLM Lasso Regression
#cross validation with lasso regression
glmRet_cv <- cv.glmnet(data.matrix(xD), lcdfTrn$actualReturn, family="gaussian",  alpha=1)
glmRet_cv$lambda.min
glmRet_cv$lambda.1se
plot(glmRet_cv)
glmls_actRet <- glmnet(data.matrix(xD), lcdfTrn$actualReturn, family="gaussian", type.measure="mse", alpha = 1,
                  lambda = glmRet_cv$lambda.min )
#prediction of GLM Lasso  on training data
pred = predict(glmls_actRet, data.matrix(xD), s="lambda.min")
predRet_Trn <- lcdfTrn %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet= pred)
predRet_Trn <- predRet_Trn %>% mutate(tile=ntile(-predRet, 10))
predRet_Trn %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totG=sum(grade=="G") )
#prediction of GLM Lasso on test data
pred = predict(glmls_actRet, data.matrix(xD_1), s="lambda.min")
predRet_Tst <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet= pred)
predRet_Tst <- predRet_Tst %>% mutate(tile=ntile(-predRet, 10))
predRet_Tst %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totG=sum(grade=="G") )
#To compute the prediction error, RMSE
RMSE(pred, lcdfTst$actualReturn)


#GLM Ridge Regression
#ridge regression model 1
glmRet_cv_a0<- cv.glmnet(data.matrix(xD), lcdfTrn$actualReturn, family="gaussian", alpha=0)
glmRet_cv_a0$lambda.min
glmRet_cv_a0$lambda.1se
plot(glmRet_cv_a0)
glm_ridge_actRet <- glmnet(data.matrix(xD), lcdfTrn$actualReturn, family="gaussian", type.measure="mse", alpha = 0,
                  lambda = glmRet_cv_a0$lambda.min )
#prediction of GLM  on test data
pred = predict(glm_ridge_actRet, data.matrix(xD_1), s="lambda.min")
predRet_Tst <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet= pred)
predRet_Tst <- predRet_Tst %>% mutate(tile=ntile(-predRet, 10))
predRet_Tst %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totG=sum(grade=="G") )
#To compute the prediction error, RMSE
RMSE(pred, lcdfTst$actualReturn)

#ridge regression model 2
glmRet_cv_a2<- cv.glmnet(data.matrix(xD), lcdfTrn$actualReturn, family="gaussian", alpha=0.2)
glmRet_cv_a2$lambda.min
glmRet_cv_a2$lambda.1se
plot(glmRet_cv_a2)
glm_ridge2_actRet <- glmnet(data.matrix(xD), lcdfTrn$actualReturn, family="gaussian", type.measure="mse", alpha=0.2,
                  lambda = glmRet_cv_a2$lambda.min )
#prediction of Ridge regrssion 2  on test data
pred = predict(glm_ridge2_actRet, data.matrix(xD_1), s="lambda.min")
predRet_Tst <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet= pred)
predRet_Tst <- predRet_Tst %>% mutate(tile=ntile(-predRet, 10))
predRet_Tst %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totG=sum(grade=="G"))
#To compute the prediction error, RMSE
RMSE(pred, lcdfTst$actualReturn)

#ridge regression model 3
glmRet_cv_a5<- cv.glmnet(data.matrix(xD), lcdfTrn$actualReturn, family="gaussian", alpha=0.5)
glmRet_cv_a5$lambda.min
glmRet_cv_a5$lambda.1se
plot(glmRet_cv_a5)
glm_ridge3_actRet <- glmnet(data.matrix(xD), lcdfTrn$actualReturn, family="gaussian", type.measure="mse", alpha=0.5,
                  lambda = glmRet_cv_a5$lambda.min )
#prediction of Ridge regrssion 3  on test data
pred = predict(glm_ridge3_actRet, data.matrix(xD_1), s="lambda.min")
predRet_Tst <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet= pred)
predRet_Tst <- predRet_Tst %>% mutate(tile=ntile(-predRet, 10))
predRet_Tst %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totG=sum(grade=="G") )
#To compute the prediction error, RMSE
RMSE(pred, lcdfTst$actualReturn)

#Model 4 with non-zero coefficients
vars_nz<-as.matrix(coef(glmRet_cv_a5, s="lambda.1se"))
vars_nz <- vars_nz[-1,1]
glmRet_cv_a5_nzv<- cv.glmnet(data.matrix(xD %>% select(names(vars_nz))), lcdfTrn$actualReturn, family="gaussian")
glmRet_a5_nzv <- glmnet(data.matrix(xD %>% select(names(vars_nz))), lcdfTrn$actualReturn, family="gaussian", type.measure="mse", lambda = glmRet_cv_a5_nzv$lambda.min )
#prediction of regression 3  on test data
pred = predict(glmRet_a5_nzv, data.matrix(xD_1), s="lambda.min")
predRet_Tst <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet= pred)
predRet_Tst <- predRet_Tst %>% mutate(tile=ntile(-predRet, 10))
predRet_Tst %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totG=sum(grade=="G") )
#To compute the prediction error, RMSE
RMSE(pred, lcdfTst$actualReturn)



############Random Forest############
#random forest model to predict actual returns on Training data
rfModel_Ret <- ranger(actualReturn ~., data=subset(lcdfTrn, select=-c(annRet, actualTerm, loan_status)), num.trees = 500, importance='permutation')

plot ( (predict(rfModel_Ret, lcdfTrn))$predictions, lcdfTrn$actualReturn)
plot ( (predict(rfModel_Ret, lcdfTst))$predictions, lcdfTst$actualReturn)

#Performance by deciles on Training data
predRet_Trn <- lcdfTrn %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet=(predict(rfModel_Ret, lcdfTrn))$predictions)
predRet_Trn <- predRet_Trn %>% mutate(tile=ntile(-predRet, 10))
predRet_Trn %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B"), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"),  totG=sum(grade=="G"))

#Performance by deciles on Test data
predRet_Tst <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet=(predict(rfModel_Ret, lcdfTst))$predictions)
predRet_Tst <- predRet_Tst %>% mutate(tile=ntile(-predRet, 10))
predRet_Tst %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B"), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"),  totG=sum(grade=="G"))

# To calculate the RMSE
rfPredRet_tst <- predict(rfModel_Ret, lcdfTst)
sqrt(mean( (rfPredRet_tst$predictions - lcdfTrn$actualReturn)^2))


############XGBOOST MODEL############
lcdf_actRet <- subset(lcdf, select=-c(annRet, actualTerm, loan_status, total_pymnt,  issue_d))

#using one-hot encoding
fdum <- dummyVars(~.,data=lcdf_actRet %>% select(-actualReturn))
dxlcdf <- predict(fdum, lcdf_actRet) #Matrix for x (lcdf_actRet)
actRetlcdf <- lcdf_actRet$actualReturn #Matrix for y

#Training, test subsets for xgboost (See trnIndex at the beginning)
dxlcdfTrn <- dxlcdf[trnIndex,] #Trn-x
dxlcdfTst <- dxlcdf[-trnIndex,] #Tst-x
actlcdfTrn <- actRetlcdf[trnIndex] #Trn-y
actlcdfTst <- actRetlcdf[-trnIndex] #Tst-y
eva_lcdfTrn <- lcdf[trnIndex,] #for evaluation
eva_lcdfTst <- lcdf[-trnIndex,] #for evaluation

#make data matrix
dxTrn<-xgb.DMatrix(dxlcdfTrn, label=actlcdfTrn)
dxTst<-xgb.DMatrix(dxlcdfTst, label=actlcdfTst)
xgbWatchlist <- list(train = dxTrn, eval = dxTst)

# hyper parameters
xgbParamGrid <- expand.grid(
max_depth = c(2, 5, 6),
eta = c(0.01, 0.001, 0.1))

# For loop for getting the best parameters
for(i in 1:nrow(xgbParamGrid)) {
  xgb_tune <- xgb.cv(data = dxTrn,objective= "reg:squarederror",
                     nrounds=50,
                     nfold = 5,
                     eta=xgbParamGrid$eta[i],
                     max_depth=xgbParamGrid$max_depth[i],
                     early_stopping_rounds= 10)
  xgbParamGrid$bestTree[i] <- xgb_tune$evaluation_log[xgb_tune$best_iteration]$iter
 xgbParamGrid$RMSE_Error[i] <- xgb_tune$evaluation_log[xgb_tune$best_iteration]$test_rmse_mean
}
# to view the parameters for the best perf
xgbParamGrid[which.min(xgbParamGrid$RMSE_Error),]
xgbParamGrid %>% view()

# based on the above for loop, we get the best parameters is applied below to get the best model
xgbParams <- list (
  booster = "gbtree",
  objective ="reg:squarederror",
  nfold = 5
)
xgb_actRet <- xgb.train( xgbParams, dxTrn, nrounds = 500, xgbWatchlist, early_stopping_rounds = 10 , max_depth=5, eta=0.1)
#best iteration
xgb_actRet$best_iteration
#variable importance
xgb.importance(model=xgb_actRet) %>% view()
# predictions from the results of xgb_actRet
xpred_actRet<-predict(xgb_actRet, dxTrn)
head(xpred_actRet)

# Predictions On Training data
predXgbRet_Trn <- eva_lcdfTrn %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>%
  mutate(predXgbRet=xpred_actRet)
predXgbRet_Trn <- predXgbRet_Trn %>% mutate(tile=ntile(-predXgbRet, 10))
predXgbRet_Trn %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predXgbRet), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B"), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"),  totG=sum(grade=="G"))

# Predictions On Test data
predXgbRet_Tst <- eva_lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>%
  mutate(predXgbRet1=predict(xgb_actRet, dxTst))
predXgbRet_Tst <- predXgbRet_Tst %>% mutate(tile=ntile(-predXgbRet1, 10))
predXgbRet_Tst %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predXgbRet1), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B"), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"),  totG=sum(grade=="G"))

#plotting the xgboost model
gr<-xgb.plot.tree(model=xgb_actRet, trees=1, render=FALSE)
export_graph(gr, 'tree.pdf', width=1500, height=1900)

pred = predict(xgb_actRet, dxTst)
#To compute the prediction error, RMSE
RMSE(pred, lcdfTst$actualReturn)
#The lower the RMSE, the better the model
```


```{r Question 4}

#Model1 Predict Loan status : xgb_lsM1
# Returns performance by decile
fnDecileReturnsPerformance( predict(xgb_lsM1, dxTst, type="response"), lcdfTst  ) 

#Model2 Predict the actual returns : xgb_actRet
# Returns performance by decile
predXgbRet_Tst %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predXgbRet1), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B"), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"),  totG=sum(grade=="G")) 


#M1 model
xpredTst<-predict(xgb_lsM1, dxTst)
scoreTst_xgb_ls <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(score=xpredTst)
scoreTst_xgb_ls <- scoreTst_xgb_ls %>% mutate(tile=ntile(-score, 10))
scoreTst_xgb_ls %>% group_by(tile) %>% summarise(count=n(), avgSc=mean(score), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") ,  totG=sum(grade=="G"))

#M2 Model
predXgbRet_Tst <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% 
mutate( predXgbRet=predict(xgb_actRet, dxTst ))
predXgbRet_Tst <- predXgbRet_Tst %>% mutate(tile=ntile(-predXgbRet, 10))
predXgbRet_Tst %>% group_by(tile) %>% summarise(count=n(), avgPredRet=mean(predXgbRet), 
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), 
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), 
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totG=sum(grade=="G") )

#Consider top d deciles from M2, ranked by M1 scores
pRetSc <- predXgbRet_Tst %>% mutate(poScore=scoreTst_xgb_ls$score)
pRet_d <- pRetSc %>% filter(tile<=1)
pRet_d<- pRet_d %>% mutate(tile2=ntile(-poScore, 20))
pRet_d %>% group_by(tile2) %>% summarise(count=n(), avgPredRet=mean(predXgbRet), ,
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), 
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totG=sum(grade=="G") )

#added the column expReturn
pRet_d<- pRet_d %>% mutate(expRet=predXgbRet*poScore)
pRet_d<- pRet_d %>% mutate(tile2=ntile(-expRet, 20))
pRet_d %>% group_by(tile2) %>% summarise(count=n(), avgPredRet=mean(predXgbRet), avgexpRet= mean(expRet),
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), 
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), 
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") , totG=sum(grade=="G"))


```


```{r Question 5}

##### RANDOM FOREST MODEL##########

#Modeling loan_status on lower grade loans - rf (ranger)
lg_lcdfTst<-lcdfTst %>% filter(grade=='C'| grade=='D'| grade== 'E'| grade== 'F'| grade== 'G')
lg_lcdfTrn<- lcdfTrn %>% filter(grade=='C'| grade=='D'| grade== 'E'| grade== 'F'| grade== 'G')
rf_M1_lg <- ranger(loan_status ~., data=subset(lg_lcdfTrn, select=-c(annRet, actualTerm, actualReturn)), num.trees =200, 
probability=TRUE, importance='permutation') 

#Predictions on Training Data
lg_scoreTrnRF <- lg_lcdfTrn %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% 
mutate(score=(predict(rf_M1_lg,lg_lcdfTrn))$predictions[,"Fully Paid"])
lg_scoreTrnRF <- lg_scoreTrnRF %>% mutate(tile=ntile(-score, 10))
lg_scoreTrnRF %>% group_by(tile) %>% summarise(count=n(), avgSc=mean(score), 
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), 
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), 
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") , totG=sum(grade=="G"))

#Predictions on Test data
lg_scoreTstRF <- lg_lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% 
mutate(score=(predict(rf_M1_lg,lg_lcdfTst))$predictions[,"Fully Paid"])

lg_scoreTstRF <- lg_scoreTstRF %>% mutate(tile=ntile(-score, 10))
lg_scoreTstRF %>% group_by(tile) %>% summarise(count=n(), avgSc=mean(score), 
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), 
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), 
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") , totG=sum(grade=="G"))

#plot for predictions
plot (predict(rf_M1_lg, lg_lcdfTst)$predictions[1:length(lg_lcdfTst$actualReturn)], lg_lcdfTst$actualReturn)


##### XGBOOST MODEL##########
#data transformations
lcdf_xgb <- lcdf%>% filter(grade=='C'| grade=='D'| grade== 'E'| grade== 'F'| grade== 'G')
nr<-nrow(lcdf_xgb)
trnIndex = sample(1:nr, size = round(0.7*nr), replace=FALSE)
lcdfTrn <- lcdf_xgb[trnIndex, ]
lcdfTst <- lcdf_xgb[-trnIndex, ]
# subset of data without leakage variables
lcdf_act <- subset(lcdf_xgb, select=-c(loan_status,actualTerm, actualReturn, total_pymnt, annRet, issue_d))
#using one-hot encoding
fdum<-dummyVars(~.,data=lcdf_act)
dxlcdf<-predict(fdum, lcdf_act) #Matrix for x 
fplcdf<-class2ind(as.factor(lcdf_xgb$loan_status), drop2nd = TRUE) #Matrix for y : loan status
#For actual returns
actRetlcdf <- lcdf_xgb$actualReturn
#Training, test subsets for xgboost 
# For loan status
dxlcdfTrn <- dxlcdf[trnIndex,] #Trn-x
dxlcdfTst <- dxlcdf[-trnIndex,] #Tst-x
fplcdfTst<-fplcdf[-trnIndex] # Tst-y
fplcdfTrn<-fplcdf[trnIndex] # Trn-y
# For actual returns
actlcdfTrn <- actRetlcdf[trnIndex] #Trn-y
actlcdfTst <- actRetlcdf[-trnIndex] #Tst-y


### XGBOOST For Predicting Loan Status ###
#make data matrix
dxTrn<-xgb.DMatrix(dxlcdfTrn, label=fplcdfTrn)
dxTst<-xgb.DMatrix(dxlcdfTst, label=fplcdfTst)
xgbWatchlist <- list(train = dxTrn, eval = dxTst)

#hyper parameters
xgbParamGrid <- expand.grid(
max_depth = c(4, 5, 6),
eta = c(0.01, 0.001, 0.1) )

for(i in 1:nrow(xgbParamGrid)) {
xgb_tune <- xgboost(data=dxTrn, objective = "binary:logistic", nrounds=50, eta=xgbParamGrid$eta[i], 
max_depth=xgbParamGrid$max_depth[i], early_stopping_rounds = 10, eval_metric = "auc", min_child_weight =1 )
xgbParamGrid$bestTree[i] <- xgb_tune$evaluation_log[xgb_tune$best_iteration]$iter
xgbParamGrid$bestPerf[i] <- xgb_tune$evaluation_log[xgb_tune$best_iteration]$train_auc
}

# to view the parameters for the best perf
xgbParamGrid[which.max(xgbParamGrid$bestPerf),]
xgbParamGrid %>% view()
# based on the above for loop, we get the best parameters which is applied below to get the best model
xgbParams <- list (
  booster = "gbtree",
  objective ="binary:logistic",
  min_child_weight=1,
  eval_metric = "auc",
  eval_metric = "error"
)
xgb_ls_lowgrd <- xgb.train( xgbParams, dxTrn, nrounds = 500, xgbWatchlist, early_stopping_rounds = 10 , max_depth=6, eta=0.1)
#best iteration
xgb_ls_lowgrd$best_iteration
#variable importance
xgb.importance(model=xgb_ls_lowgrd) %>% view()
#Training predictions
xpred_ls_lg_Trn <- predict(xgb_ls_lowgrd,dxTrn)
#Testing predictions
xpred_ls_lg_Tst <- predict(xgb_ls_lowgrd,dxTst)


### XGBOOST For Actual Return Predictions ###
#make data matrix
dxTrn1<-xgb.DMatrix(dxlcdfTrn, label=actlcdfTrn)
dxTst1<-xgb.DMatrix(dxlcdfTst, label=actlcdfTst)
xgbWatchlist <- list(train = dxTrn1, eval = dxTst1)

# hyper parameters
xgbParamGrid <- expand.grid(
max_depth = c(2,5),
eta = c(0.01, 0.001, 0.1))

# For loop for getting the best parameters
for(i in 1:nrow(xgbParamGrid)) {
  xgb_tune <- xgb.cv(data = dxTrn1,objective= "reg:squarederror",
                     nrounds=50,
                     nfold = 5,
                     eta=xgbParamGrid$eta[i],
                     max_depth=xgbParamGrid$max_depth[i],
                     early_stopping_rounds= 10)
  xgbParamGrid$bestTree[i] <- xgb_tune$evaluation_log[xgb_tune$best_iteration]$iter
 xgbParamGrid$RMSE_Error[i] <- xgb_tune$evaluation_log[xgb_tune$best_iteration]$test_rmse_mean
}

# to view the parameters for the best perf
xgbParamGrid[which.min(xgbParamGrid$RMSE_Error),]
xgbParamGrid %>% view()

# based on the above for loop, we get the best parameters is applied below to get the best model
xgbParams <- list (
  booster = "gbtree",
  objective ="reg:squarederror",
  nfold = 5
)
xgb_actRet_lg <- xgb.train( xgbParams, dxTrn, nrounds = 500, xgbWatchlist, early_stopping_rounds = 10 , max_depth=5, eta=0.1)

xgb.importance(model=xgb_actRet_lg) %>% view()



#M1: For Loan Status
xpredTst<-predict(xgb_ls_lowgrd, dxTst)
scoreTst_xgb_ls <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(score=xpredTst)
scoreTst_xgb_ls <- scoreTst_xgb_ls %>% mutate(tile=ntile(-score, 10))
scoreTst_xgb_ls %>% group_by(tile) %>% summarise(count=n(), avgSc=mean(score), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") ,  totG=sum(grade=="G"))

#M2: For Actual Returns
xpredTst_actRet = predict(xgb_actRet_lg, dxTst1 )
predXgbRet_Tst <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% 
mutate( predXgbRet=xpredTst_actRet)
predXgbRet_Tst <- predXgbRet_Tst %>% mutate(tile=ntile(-predXgbRet, 10))
predXgbRet_Tst %>% group_by(tile) %>% summarise(count=n(), avgPredRet=mean(predXgbRet), 
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), 
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), 
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totG=sum(grade=="G") )

#Consider top d deciles from M2, ranked by M1 scores
pRetSc <- predXgbRet_Tst %>% mutate(poScore=scoreTst_xgb_ls$score)
pRet_d <- pRetSc %>% filter(tile<=1)
pRet_d<- pRet_d %>% mutate(tile2=ntile(-poScore, 20))

#added the column expReturn
pRet_d<- pRet_d %>% mutate(expRet=predXgbRet*poScore)
pRet_d<- pRet_d %>% mutate(tile2=ntile(-expRet, 20))
pRet_d %>% group_by(tile2) %>% summarise(count=n(), avgPredRet=mean(predXgbRet), avgexpRet= mean(expRet),
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), 
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), 
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") , totG=sum(grade=="G"))

#plot for predictions for both model
plot (xpredTst, lcdfTst$loan_status)
plot (xpredTst_actRet, lcdfTst$actualReturn)

```